# 🎣 Clickbait Detector - 낚시성 기사 판별 서비스



## 📘 소개

Clickbait Detector는 온라인 뉴스 기사의 제목과 본문을 분석하여 **낚시성 여부를 판별**하고,  
낚시성 기사일 경우 **이유를 생성**, 비낚시성 기사일 경우에는 **요약을 제공**하는 인공지능 기반 서비스입니다.  
뉴스 콘텐츠의 신뢰도를 높이고 사용자에게 명확한 정보를 전달하는 것을 목표로 합니다.



## 🎯 목표

-  **낚시성 기사 판별**: Fine-Tuning된 모델을 통해 뉴스 기사의 낚시성 여부를 분류합니다.  
-  **낚시성 이유 생성**: RAG(Retrieval-Augmented Generation)를 활용해 외부 정보 기반의 설명을 생성합니다.  
-  **비낚시성 기사 요약**: 요약 모델을 통해 중요한 정보만 간결하게 전달합니다.


## 📌 주요 기능

- 뉴스 제목 및 본문 기반의 낚시성 여부 판별  
- Clickbait / Not Clickbait 이진 분류  
- 낚시성 판단 시 그 이유 생성  
- 비낚시성 판단 시 핵심 내용 요약  
- RESTful API 제공 (향후 웹 UI 연동 예정)



## ⚙️ 기술 스택

| 구분 | 기술 |
|------|------|
| Backend | Python, FastAPI |
| AI/ML | Hugging Face Transformers (BERT, LLaMA), PyTorch |
| Data | AIHub Clickbait Detection Dataset (JSON) |



## 🧾 데이터셋 예시 (JSON)

```json
{
  "newsTitle": "연합뉴스 포털 노출중단 위기에 노조 \"최악의 참사\"",
  "newsContent": "포털 뉴스제휴평가위원회제휴평가위가 연합뉴스에 한 달 포털 노출중단 제재 및 재평가퇴출평가에 해당하는 벌점을 의결하자 전국언론노조 연합뉴스 지부연합뉴스 노조가 입장을 냈다 (생략)",
  "clickbaitClass": 0
}
```

- `newsTitle` + `newsContent`를 하나의 입력으로 구성하여 분류 모델에 전달  
- `clickbaitClass`: 1 → 낚시성, 0 → 일반 기사


## 🔬 학습 및 추론 방식 (BERT vs LLaMA)

### ✅ BERT

- `title + content`를 tokenizer로 인코딩 후 모델에 입력  
- `[CLS]` 토큰의 출력 벡터를 기반으로 softmax → 이진 분류  
- 예측 결과 예시: `[0.12, 0.88]` → label = `1 (Clickbait)`

### ✅ LLaMA

- Prompt 기반 입력: `"Classify: 제목 본문\nAnswer:"`  
- 다음 토큰으로 `"Clickbait"` 또는 `"Not Clickbait"`를 생성  
- 생성된 텍스트를 파싱하여 결과 판단


## 📊 모델 성능 비교

| 모델 | Accuracy | F1 Score | Precision | Recall |
|------|----------|----------|-----------|--------|
| **BERT (분류 전용)** | 75.81% | 75.49% | 75.80% | 75.81% |
| **LLaMA (생성형 모델)** | **76.98%** | **79.31%** | **81.75%** | **77.02%** |

📌 LLaMA는 모든 측면에서 BERT를 상회하는 성능을 보였으며,  
특히 **Precision 81.75%**는 낚시성 기사 판별에서 **높은 신뢰도**를 의미합니다.  
또한 F1 Score 역시 **LLaMA가 79.31%로 BERT를 초과**했습니다.



## ❓ 왜 LLaMA를 선택했는가?

1. **긴 문서 입력 수용**  
   - BERT는 입력 토큰 길이에 제한(512 tokens)이 있어 긴 기사 본문 처리에 불리합니다.  
   - LLaMA는 최대 8,000 tokens 이상의 입력을 처리할 수 있어 긴 뉴스 기사도 손실 없이 분류 가능했습니다.

2. **고차원 언어 이해 및 추론 능력**  
   - Clickbait 여부는 단순 단어 매칭이 아닌 **은유, 과장, 맥락 해석**이 필요한 작업입니다.  
   - LLaMA는 대규모 사전학습을 통해 **추론(reasoning) 능력**이 뛰어나 복잡한 기사도 효과적으로 분류합니다.

3. **확장성 높은 멀티태스킹 구조**  
   - LLaMA는 분류뿐 아니라 프롬프트 기반 생성도 가능하여 다음과 같은 작업을 통합할 수 있습니다:
     - `reason:` → 낚시성 판단 이유 생성  
     - `summarize:` → 비낚시성 기사 요약  
   - 향후 모든 기능을 하나의 모델로 통합할 수 있는 **확장성과 유지보수 측면에서 유리**합니다.

---
